
This graduate student will engage in image- and text-based analysis to determine the content and types of immigration-related documents in a large digital collection.

 

Given a training corpus of several thousand images in several hundred documents, the primary task will be to predict which of a number of different document classes (I-589 forms, marriage certificates, passports, photographs, etc.) any given document belongs to. Additionally, they will develop features to segment groups of related pages apart. The data model will be provided based on domain expertise.

 

Using either TensorFlow or PyTorch, they will test a number of different image embedding models for the task, from traditional CNNs such as ResNet, mixed-modal models like CLIP, and they will explore document-layout models such as those created in the PubLayNet dataset and used in the LayoutParser platform.

 

This work will be done on NYU's state-of-the-art Greene supercomputer, so students should have some previous experiment working in an HPC environment.
